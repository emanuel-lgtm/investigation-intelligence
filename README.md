# ğŸ” Investigation Intelligence System

A comprehensive AI-powered investigation platform that ingests documents from multiple sources, performs deep analysis, and generates detailed investigative reports with mind mapping, relationship discovery, and self-prompting intelligence.

## ğŸ“‹ Overview

This system transforms raw documents, audio, video, and data files into structured intelligence reports with:
- âœ… Unlimited file size support
- âœ… Multi-source ingestion (Google Drive, Dropbox, Local, External HD)
- âœ… Advanced AI analysis (V7-style extraction + NotebookLM reasoning + Investigation layer)
- âœ… Automatic mind mapping and relationship graphs
- âœ… Self-prompting: discovers unasked questions and hidden relationships
- âœ… Professional PDF reports with embedded visualizations

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INGESTION LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Google  â”‚  â”‚ Dropbox  â”‚  â”‚  Local   â”‚  â”‚ External â”‚       â”‚
â”‚  â”‚  Drive   â”‚  â”‚   API    â”‚  â”‚  Folder  â”‚  â”‚    HD    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â–¼                                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚  File Type Router       â”‚                        â”‚
â”‚              â”‚  (PDF/DOC/XLS/Audio/    â”‚                        â”‚
â”‚              â”‚   Video/Images)         â”‚                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NORMALIZATION LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   OCR      â”‚  â”‚ Transcribe â”‚  â”‚  Parser    â”‚               â”‚
â”‚  â”‚ (Tesseract)â”‚  â”‚ (Whisper)  â”‚  â”‚ (openpyxl) â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                        â–¼                                         â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚              â”‚  Unified JSON Store  â”‚                          â”‚
â”‚              â”‚  (Chunked Streaming) â”‚                          â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ANALYSIS ENGINE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              LAYER 1: EXTRACTION (V7-Style)              â”‚  â”‚
â”‚  â”‚  â€¢ Custom field detection                                â”‚  â”‚
â”‚  â”‚  â€¢ Entity extraction (people, companies, accounts)       â”‚  â”‚
â”‚  â”‚  â€¢ Structured data mining                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           LAYER 2: CONTEXT (NotebookLM-Style)            â”‚  â”‚
â”‚  â”‚  â€¢ Cross-document reasoning                              â”‚  â”‚
â”‚  â”‚  â€¢ Timeline construction                                 â”‚  â”‚
â”‚  â”‚  â€¢ Summaries & meaning extraction                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         LAYER 3: INVESTIGATION (Custom Logic)            â”‚  â”‚
â”‚  â”‚  â€¢ Collusion detection                                   â”‚  â”‚
â”‚  â”‚  â€¢ Inconsistency analysis                                â”‚  â”‚
â”‚  â”‚  â€¢ Anomaly detection                                     â”‚  â”‚
â”‚  â”‚  â€¢ Deception indicators                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INTELLIGENCE LAYER                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Mind Map Builder       â”‚  â”‚  Self-Prompting Engine   â”‚    â”‚
â”‚  â”‚   â€¢ Graph construction   â”‚  â”‚  â€¢ Unasked questions     â”‚    â”‚
â”‚  â”‚   â€¢ Relationship linking â”‚  â”‚  â€¢ Hidden relationships  â”‚    â”‚
â”‚  â”‚   â€¢ Network visualizationâ”‚  â”‚  â€¢ Hypotheses generation â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OUTPUT LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚    PDF Report Generator  â”‚  â”‚  JSON/Graph Exports      â”‚    â”‚
â”‚  â”‚    (ReportLab)           â”‚  â”‚  â€¢ case_summary.json     â”‚    â”‚
â”‚  â”‚    â€¢ Executive summary   â”‚  â”‚  â€¢ graph.json            â”‚    â”‚
â”‚  â”‚    â€¢ Timeline            â”‚  â”‚  â€¢ embeddings (optional) â”‚    â”‚
â”‚  â”‚    â€¢ Mind map (embedded) â”‚  â”‚  â€¢ GraphML export        â”‚    â”‚
â”‚  â”‚    â€¢ Evidence tables     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”‚    â€¢ Hypotheses          â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
investigation-system/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml                   # Main configuration
â”‚   â””â”€â”€ credentials/                  # API keys and credentials
â”‚       â”œâ”€â”€ google_drive_credentials.json
â”‚       â””â”€â”€ dropbox_token.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                       # Main orchestrator
â”‚   â”œâ”€â”€ ingestion/                    # Data ingestion modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                  # Base ingestion class
â”‚   â”‚   â”œâ”€â”€ google_drive.py          # Google Drive connector
â”‚   â”‚   â”œâ”€â”€ dropbox.py               # Dropbox connector
â”‚   â”‚   â”œâ”€â”€ local_folder.py          # Local filesystem
â”‚   â”‚   â””â”€â”€ external_hd.py           # External drive handler
â”‚   â”œâ”€â”€ processing/                   # File processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ router.py                # File type router
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py         # PDF handling + OCR
â”‚   â”‚   â”œâ”€â”€ document_processor.py    # DOC/DOCX/TXT
â”‚   â”‚   â”œâ”€â”€ spreadsheet_processor.py # XLS/XLSX/Numbers
â”‚   â”‚   â”œâ”€â”€ audio_processor.py       # Audio transcription
â”‚   â”‚   â”œâ”€â”€ video_processor.py       # Video transcription
â”‚   â”‚   â””â”€â”€ image_processor.py       # Image OCR
â”‚   â”œâ”€â”€ normalization/               # Data normalization
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ normalizer.py           # Main normalizer
â”‚   â”‚   â””â”€â”€ json_store.py           # Unified JSON storage
â”‚   â”œâ”€â”€ analysis/                    # AI analysis layers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extraction_layer.py     # Layer 1: V7-style extraction
â”‚   â”‚   â”œâ”€â”€ context_layer.py        # Layer 2: NotebookLM reasoning
â”‚   â”‚   â”œâ”€â”€ investigation_layer.py  # Layer 3: Investigation logic
â”‚   â”‚   â””â”€â”€ llm_interface.py        # GPT-4/5 interface
â”‚   â”œâ”€â”€ intelligence/                # Advanced intelligence
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mind_map.py             # Mind map builder
â”‚   â”‚   â”œâ”€â”€ graph_builder.py        # Relationship graph
â”‚   â”‚   â”œâ”€â”€ self_prompting.py       # Question generation
â”‚   â”‚   â””â”€â”€ hypothesis_generator.py  # Hidden relationship detection
â”‚   â”œâ”€â”€ output/                      # Report generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_generator.py        # PDF report creation
â”‚   â”‚   â”œâ”€â”€ json_exporter.py        # JSON exports
â”‚   â”‚   â””â”€â”€ graph_exporter.py       # Graph exports (JSON/GraphML)
â”‚   â””â”€â”€ utils/                       # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py               # Logging setup
â”‚       â”œâ”€â”€ chunking.py             # Chunked file processing
â”‚       â””â”€â”€ helpers.py              # Helper functions
â”œâ”€â”€ tests/                           # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”œâ”€â”€ test_processing.py
â”‚   â”œâ”€â”€ test_analysis.py
â”‚   â””â”€â”€ test_output.py
â”œâ”€â”€ data/                            # Data directory
â”‚   â”œâ”€â”€ raw/                        # Raw ingested files
â”‚   â”œâ”€â”€ normalized/                 # Normalized JSON
â”‚   â”œâ”€â”€ analysis/                   # Analysis results
â”‚   â””â”€â”€ output/                     # Final reports
â””â”€â”€ examples/                        # Example cases
    â””â”€â”€ sample_case/
        â”œâ”€â”€ input_files/
        â””â”€â”€ expected_output/
```

## ğŸ”§ Installation

### Prerequisites

```bash
# System requirements
- Python 3.10+
- macOS (primary target)
- OpenAI API key (for GPT-4/5)
- Optional: Google Drive API credentials
- Optional: Dropbox API token
```

### Setup

```bash
# 1. Clone or create project directory
mkdir investigation-system
cd investigation-system

# 2. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux

# 3. Install dependencies
pip install -r requirements.txt

# 4. Install system dependencies (macOS)
brew install tesseract         # OCR
brew install ffmpeg            # Audio/video processing
brew install graphviz          # Graph visualization

# 5. Configure credentials
cp config/config.yaml.example config/config.yaml
# Edit config.yaml with your API keys

# 6. Set up API credentials
# - Place google_drive_credentials.json in config/credentials/
# - Place dropbox_token.txt in config/credentials/
# - Add OPENAI_API_KEY to environment or config.yaml
```

## ğŸš€ Usage

### Basic Usage

```python
from src.main import InvestigationSystem

# Initialize system
system = InvestigationSystem(config_path="config/config.yaml")

# Create a new case
case = system.create_case(
    case_id="CASE_001",
    name="Investigation Alpha",
    description="Fraud investigation for Company X"
)

# Ingest from multiple sources
system.ingest_from_google_drive(
    folder_id="...",
    case_id="CASE_001"
)

system.ingest_from_dropbox(
    folder_path="/Evidence/Case001",
    case_id="CASE_001"
)

system.ingest_from_local(
    folder_path="/Users/you/Documents/Evidence",
    case_id="CASE_001"
)

# Process and analyze
system.process_case("CASE_001")

# Generate report
report_path = system.generate_report(
    case_id="CASE_001",
    output_format=["pdf", "json", "graph"]
)

print(f"Report generated: {report_path}")
```

### CLI Usage

```bash
# Create new case
python -m src.main create-case --name "Investigation Alpha" --id CASE_001

# Ingest from Google Drive
python -m src.main ingest \
    --source google_drive \
    --folder-id "abc123" \
    --case-id CASE_001

# Ingest from local folder
python -m src.main ingest \
    --source local \
    --path "/path/to/evidence" \
    --case-id CASE_001

# Process case
python -m src.main process --case-id CASE_001

# Generate report
python -m src.main report \
    --case-id CASE_001 \
    --format pdf,json,graph \
    --output ./reports/
```

## ğŸ“Š Data Flow

### 1. Ingestion Phase
```
Source â†’ Download/Stream â†’ Type Detection â†’ Queue for Processing
```

### 2. Processing Phase
```
Raw File â†’ Parser/OCR/Transcribe â†’ Chunked Processing â†’ JSON Record
```

### 3. Normalization Phase
```json
{
  "case_id": "CASE_001",
  "source_id": "gdrive_abc123",
  "type": "pdf",
  "origin": "google_drive",
  "location": "page_5",
  "speaker": null,
  "text": "Extracted content here...",
  "metadata": {
    "filename": "contract.pdf",
    "created": "2024-01-15",
    "modified": "2024-03-20",
    "author": "John Doe"
  }
}
```

### 4. Analysis Phase (3 Layers)

**Layer 1: Extraction**
- Custom fields: parties, dates, amounts, accounts
- Entity recognition: people, companies, locations
- Structured data extraction

**Layer 2: Context**
- Cross-reference documents
- Build timeline of events
- Generate summaries and meaning

**Layer 3: Investigation**
- Detect inconsistencies
- Flag suspicious patterns
- Identify potential collusion

### 5. Intelligence Phase
- Build relationship graph
- Generate mind map
- Self-prompt for unasked questions
- Propose hypotheses

### 6. Output Phase
- PDF report (12+ sections)
- JSON exports
- Graph data (JSON/GraphML)

## ğŸ¯ Key Features

### 1. Multi-Source Ingestion
```python
# Supports unlimited file sizes via chunked streaming
system.ingest_from_google_drive(folder_id="...")
system.ingest_from_dropbox(folder_path="...")
system.ingest_from_local(folder_path="...")
system.ingest_from_external_hd(mount_path="/Volumes/Evidence")
```

### 2. Comprehensive File Support
- **Documents**: PDF, DOC/DOCX, TXT, HTML, Markdown
- **Data**: JSON, CSV, XLS/XLSX, Apple Numbers
- **Media**: JPG/PNG/TIFF, MP3/WAV/M4A, MP4/MOV
- **Special**: Screen recordings, voice memos, scanned documents

### 3. Three-Layer Analysis
- **V7-Style Extraction**: Unlimited custom fields
- **NotebookLM Context**: Cross-document reasoning
- **Investigation Logic**: Collusion, deception, anomalies

### 4. Self-Prompting Intelligence
**Unasked Questions:**
- "Who authorized this transfer?"
- "Why is Company X mentioned only in internal logs?"
- "Is there missing documentation for payment #442?"

**Hidden Relationships:**
- "Person C may act as intermediary between A and B"
- "Invoices 17-19 coincide with unusually high chat activity"

### 5. Mind Mapping & Visualization
- Automatic relationship graph
- Visual mind map embedded in PDF
- Export formats: JSON, GraphML, PNG

### 6. Professional Reporting
12-section PDF report:
1. Cover page
2. Executive summary
3. Key entities & roles
4. Timeline of events
5. Context & meaning
6. Collusion/impropriety analysis
7. Structured data tables
8. Mind-map diagram
9. Unasked questions
10. Hidden relationships
11. Evidence appendix
12. Next steps

## ğŸ” Security & Privacy

- All processing happens locally (except LLM API calls)
- API keys stored securely in config/credentials/
- Optional: Use local LLM (Ollama/LLaMA) instead of OpenAI
- Data encryption at rest (optional)
- Audit logging for all operations

## ğŸ› ï¸ Configuration

### config.yaml
```yaml
system:
  case_dir: "./data"
  temp_dir: "./data/temp"
  max_workers: 4
  
llm:
  provider: "openai"  # or "anthropic" or "local"
  model: "gpt-4-turbo-preview"
  api_key: "${OPENAI_API_KEY}"
  
ingestion:
  google_drive:
    enabled: true
    credentials_path: "config/credentials/google_drive_credentials.json"
  dropbox:
    enabled: true
    token_path: "config/credentials/dropbox_token.txt"
  
processing:
  chunk_size: 10485760  # 10MB chunks
  ocr_language: "eng"
  whisper_model: "large-v3"
  
analysis:
  extraction:
    custom_fields: ["parties", "dates", "amounts", "accounts", "entities"]
  context:
    max_context_docs: 50
  investigation:
    anomaly_threshold: 0.75
    
output:
  pdf:
    include_mind_map: true
    include_evidence: true
  json:
    pretty_print: true
  graph:
    formats: ["json", "graphml", "png"]
```

## ğŸ“š API Reference

See `docs/API.md` for complete API documentation.

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test suite
pytest tests/test_analysis.py

# Run with coverage
pytest --cov=src tests/
```

## ğŸ¤ Contributing

This is a private investigation tool. For internal use only.

## ğŸ“„ License

Proprietary - All Rights Reserved

## ğŸ“ Support

For questions or issues, contact the development team.

---

**Version**: 1.0.0  
**Last Updated**: November 2025  
**Python Version**: 3.10+  
**Platform**: macOS (primary), Linux (compatible)
